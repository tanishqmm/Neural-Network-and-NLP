{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    def __init__(self):\n",
    "        self.inputLayerSize=2\n",
    "        self.outputLayerSize=1\n",
    "        self.W1= np.random.randn(self.inputLayerSize,1)\n",
    "        self.bias = 0\n",
    "\n",
    "    def sigmoid(self,z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "\n",
    "    def sigmoidprime(self,z):\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        self.z2 = X@self.W1 + self.bias\n",
    "        yHat = self.sigmoid(self.z2)\n",
    "        return yHat\n",
    "    \n",
    "    def costFunction(self,X,y):\n",
    "        yHat = self.forward(X)\n",
    "        cost = (-1/y.shape[0])*np.sum(y*np.log(yHat)+(1-y)*np.log(1-yHat),axis=0)\n",
    "        return cost\n",
    "\n",
    "    def costFunctionPrime(self,X,y):\n",
    "        yHat = self.forward(X)\n",
    "        delta = ((-y/yHat + (1-y)/(1-yHat))* self.sigmoidprime(yHat))/y.shape[0]\n",
    "        dJdW1= X.T@delta\n",
    "        dJdb = delta\n",
    "        return dJdW1,delta\n",
    "\n",
    "    def train(self, X, Y):\n",
    "        cost = self.costFunction(X,Y)\n",
    "        previous_cost = cost+1\n",
    "        wprime, bprime = self.costFunctionPrime(X,Y)\n",
    "        while(abs(previous_cost-cost)>=1e-5):\n",
    "            # print(self.weights, self.bias)\n",
    "            self.W1-=wprime\n",
    "            self.bias-=bprime\n",
    "            previous_cost = cost\n",
    "            cost = self.costFunction(X,Y)\n",
    "            # print(cost)\n",
    "            wprime, bprime = self.costFunctionPrime(X,Y)\n",
    "        return self.W1, self.bias\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = self.forward(X)\n",
    "        for i in range(len(predictions)):\n",
    "            if(predictions[i]>=0.5):\n",
    "                predictions[i] = 1\n",
    "            else:\n",
    "                predictions[i] = 0\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65857111]\n",
      "[0.59799096]\n",
      "[0.54671541]\n",
      "[0.50218008]\n",
      "[0.4628497]\n",
      "[0.42772]\n",
      "[0.3960877]\n",
      "[0.36743325]\n",
      "[0.34135624]\n",
      "[0.31753776]\n",
      "[0.29571709]\n",
      "[0.27567679]\n",
      "[0.2572325]\n",
      "[0.24022596]\n",
      "[0.22451987]\n",
      "[0.20999409]\n",
      "[0.1965428]\n",
      "[0.18407218]\n",
      "[0.17249864]\n",
      "[0.16174741]\n",
      "[0.15175131]\n",
      "[0.14244977]\n",
      "[0.13378807]\n",
      "[0.12571656]\n",
      "[0.11819014]\n",
      "[0.11116772]\n",
      "[0.1046118]\n",
      "[0.09848808]\n",
      "[0.09276514]\n",
      "[0.08741416]\n",
      "[0.08240866]\n",
      "[0.07772424]\n",
      "[0.07333847]\n",
      "[0.06923062]\n",
      "[0.06538156]\n",
      "[0.06177362]\n",
      "[0.05839043]\n",
      "[0.05521685]\n",
      "[0.05223883]\n",
      "[0.04944335]\n",
      "[0.04681831]\n",
      "[0.0443525]\n",
      "[0.04203548]\n",
      "[0.03985754]\n",
      "[0.03780965]\n",
      "[0.03588342]\n",
      "[0.034071]\n",
      "[0.03236511]\n",
      "[0.03075895]\n",
      "[0.02924618]\n",
      "[0.02782089]\n",
      "[0.02647755]\n",
      "[0.02521103]\n",
      "[0.0240165]\n",
      "[0.02288948]\n",
      "[0.02182577]\n",
      "[0.02082146]\n",
      "[0.01987287]\n",
      "[0.01897658]\n",
      "[0.01812939]\n",
      "[0.01732829]\n",
      "[0.0165705]\n",
      "[0.01585337]\n",
      "[0.01517447]\n",
      "[0.01453149]\n",
      "[0.01392228]\n",
      "[0.01334483]\n",
      "[0.01279725]\n",
      "[0.01227778]\n",
      "[0.01178476]\n",
      "[0.01131664]\n",
      "[0.01087197]\n",
      "[0.01044939]\n",
      "[0.01004762]\n",
      "[0.00966545]\n",
      "[0.00930178]\n",
      "[0.00895555]\n",
      "[0.00862577]\n",
      "[0.00831151]\n",
      "[0.00801191]\n",
      "[0.00772615]\n",
      "[0.00745346]\n",
      "[0.00719312]\n",
      "[0.00694446]\n",
      "[0.00670684]\n",
      "[0.00647967]\n",
      "[0.00626238]\n",
      "[0.00605446]\n",
      "[0.0058554]\n",
      "[0.00566474]\n",
      "[0.00548204]\n",
      "[0.00530689]\n",
      "[0.0051389]\n",
      "[0.00497771]\n",
      "[0.00482297]\n",
      "[0.00467436]\n",
      "[0.00453157]\n",
      "[0.00439432]\n",
      "[0.00426234]\n",
      "[0.00413537]\n",
      "[0.00401316]\n",
      "[0.0038955]\n",
      "[0.00378217]\n",
      "[0.00367296]\n",
      "[0.00356769]\n",
      "[0.00346617]\n",
      "[0.00336823]\n",
      "[0.00327372]\n",
      "[0.00318247]\n",
      "[0.00309435]\n",
      "[0.00300922]\n",
      "[0.00292694]\n",
      "[0.0028474]\n",
      "[0.00277048]\n",
      "[0.00269607]\n",
      "[0.00262406]\n",
      "[0.00255436]\n",
      "[0.00248687]\n",
      "[0.00242151]\n",
      "[0.00235818]\n",
      "[0.00229681]\n",
      "[0.00223733]\n",
      "[0.00217965]\n",
      "[0.00212371]\n",
      "[0.00206944]\n",
      "[0.00201678]\n",
      "[0.00196568]\n",
      "[0.00191606]\n",
      "[0.00186789]\n",
      "[0.0018211]\n",
      "[0.00177565]\n",
      "[0.0017315]\n",
      "[0.00168858]\n",
      "[0.00164687]\n",
      "[0.00160632]\n",
      "[0.0015669]\n",
      "[0.00152855]\n",
      "[0.00149126]\n",
      "[0.00145497]\n",
      "[0.00141967]\n",
      "[0.00138532]\n",
      "[0.00135188]\n",
      "[0.00131933]\n",
      "[0.00128765]\n",
      "[0.00125679]\n",
      "[0.00122675]\n",
      "[0.00119748]\n",
      "[0.00116898]\n",
      "[0.00114121]\n",
      "[0.00111415]\n",
      "[0.00108779]\n",
      "[0.0010621]\n",
      "[0.00103706]\n",
      "[0.00101266]\n",
      "[0.00098887]\n",
      "[0.00096568]\n",
      "[0.00094306]\n",
      "[0.00092101]\n",
      "[0.00089951]\n",
      "[0.00087854]\n",
      "[0.00085809]\n",
      "[0.00083814]\n",
      "[0.00081869]\n",
      "[0.0007997]\n",
      "[0.00078118]\n",
      "[0.00076311]\n",
      "[0.00074548]\n",
      "[0.00072828]\n",
      "[0.00071149]\n",
      "[0.00069511]\n",
      "[0.00067912]\n",
      "[0.00066351]\n",
      "[0.00064827]\n",
      "[0.0006334]\n",
      "[0.00061889]\n",
      "[0.00060472]\n",
      "[0.00059088]\n",
      "[0.00057738]\n",
      "[0.00056419]\n",
      "[0.00055131]\n",
      "[0.00053874]\n",
      "[0.00052646]\n",
      "[0.00051447]\n",
      "[0.00050276]\n",
      "[0.00049133]\n",
      "[0.00048016]\n",
      "[0.00046926]\n",
      "[0.0004586]\n",
      "[0.0004482]\n",
      "[0.00043804]\n",
      "[0.00042811]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-1.7497314 ],\n",
       "        [-2.18053716]]),\n",
       " array([[ 10.30169137],\n",
       "        [-12.82465148],\n",
       "        [-12.55551994],\n",
       "        [-12.6191475 ]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "And = Perceptron()\n",
    "X = np.array([[1,1],[1,0],[0,1],[0,0]])\n",
    "Y = np.array([[1],[0],[0],[0]])\n",
    "And.train(X,Y)\n",
    "print(And.predict(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
